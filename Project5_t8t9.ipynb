{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "pst_tz = pytz.timezone('America/Los_Angeles')\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_to_df(tweet_d):\n",
    "    df = pd.DataFrame(tweet_d, columns=['ID', 'Title', 'nFollowers', 'nReTweet','Ranking Score','impressions','TimeStamp'])\n",
    "    df.sort_values(by='TimeStamp',inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract Tweets\n",
    "\n",
    "def extract_tweets_into_df(file):\n",
    "    d = []\n",
    "    for line in open(file):\n",
    "        temp = []\n",
    "        t = json.loads(line)\n",
    "        temp.append(t['tweet']['id'])\n",
    "        temp.append(t['title'])\n",
    "        #temp.append(t['user'])\n",
    "        temp.append(t['author']['followers'])\n",
    "        temp.append(t['metrics']['citations']['total'])\n",
    "        temp.append(t['metrics']['ranking_score'])\n",
    "        temp.append(t['metrics']['impressions'])\n",
    "        temp.append(datetime.datetime.fromtimestamp(t['citation_date'], pst_tz))\n",
    "        d.append(temp)\n",
    "    return tweet_to_df(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_average_tweet(df):\n",
    "    tweets_by_hour = df.set_index('TimeStamp').groupby(pd.Grouper(freq='60Min'))\n",
    "\n",
    "    count_by_hour = [len(val) for key, val in tweets_by_hour]\n",
    "    total_hours = len(tweets_by_hour)\n",
    "    return len(df) / total_hours\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_y(df,window):\n",
    "    num_features = 5\n",
    "    \n",
    "    tweets_by_hour = df.set_index('TimeStamp').groupby(pd.Grouper(freq='60Min'))\n",
    "    \n",
    "    total_hours = len(tweets_by_hour)\n",
    "\n",
    "    X = np.zeros((total_hours, 5))\n",
    "    for i, (key, val) in enumerate(tweets_by_hour):\n",
    "            features = [len(val), val.nReTweet.sum(), val.nFollowers.sum(), val.nFollowers.max(), key.hour]\n",
    "            X[i, :] = features\n",
    "            \n",
    "    y = X[:, 0][window:]\n",
    "    # number of tweets is the output as well as the first feature - but have to shift by #window hours\n",
    "    X = np.nan_to_num(X)\n",
    "    X_window = np.zeros((total_hours - window, num_features * window))\n",
    "    \n",
    "    for i in range(total_hours - window):\n",
    "        X_window[i, :] = np.concatenate([X[i+k, :] for k in range(window)])\n",
    "        \n",
    "    X_window = np.nan_to_num(X_window)\n",
    "    return X_window, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>nFollowers</th>\n",
       "      <th>nReTweet</th>\n",
       "      <th>Ranking Score</th>\n",
       "      <th>impressions</th>\n",
       "      <th>TimeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>555273124673900545</td>\n",
       "      <td>#NFL #sweatshirts BRAND NEW NFL ADULT PITTSBUR...</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.920297</td>\n",
       "      <td>3055</td>\n",
       "      <td>2015-01-14 00:00:04-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>555273126972383232</td>\n",
       "      <td>Kid Writes Letter to all 32 NFL Teams, Only On...</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.044162</td>\n",
       "      <td>143</td>\n",
       "      <td>2015-01-14 00:00:04-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>555273167934337025</td>\n",
       "      <td>Premium Game Tickets for the NFL Wembley games...</td>\n",
       "      <td>3457.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.512117</td>\n",
       "      <td>3836</td>\n",
       "      <td>2015-01-14 00:00:14-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>555273550655811584</td>\n",
       "      <td>Kid Writes Letter to all 32 NFL Teams, Only On...</td>\n",
       "      <td>10658.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.886465</td>\n",
       "      <td>12096</td>\n",
       "      <td>2015-01-14 00:01:45-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>555274347745914880</td>\n",
       "      <td>♦⌂ SEATTLE #SEAHAWKS 2-TONE #NFL TEAM BREAKAWA...</td>\n",
       "      <td>833.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.945911</td>\n",
       "      <td>854</td>\n",
       "      <td>2015-01-14 00:04:55-08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                              Title  \\\n",
       "40  555273124673900545  #NFL #sweatshirts BRAND NEW NFL ADULT PITTSBUR...   \n",
       "41  555273126972383232  Kid Writes Letter to all 32 NFL Teams, Only On...   \n",
       "42  555273167934337025  Premium Game Tickets for the NFL Wembley games...   \n",
       "43  555273550655811584  Kid Writes Letter to all 32 NFL Teams, Only On...   \n",
       "44  555274347745914880  ♦⌂ SEATTLE #SEAHAWKS 2-TONE #NFL TEAM BREAKAWA...   \n",
       "\n",
       "    nFollowers  nReTweet  Ranking Score  impressions                 TimeStamp  \n",
       "40      3050.0         1       6.920297         3055 2015-01-14 00:00:04-08:00  \n",
       "41       145.0         1       4.044162          143 2015-01-14 00:00:04-08:00  \n",
       "42      3457.0         3       7.512117         3836 2015-01-14 00:00:14-08:00  \n",
       "43     10658.0         2       3.886465        12096 2015-01-14 00:01:45-08:00  \n",
       "44       833.0         1       3.945911          854 2015-01-14 00:04:55-08:00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfl_df = extract_tweets_into_df(\"data/tweets_#nfl.txt\")\n",
    "nfl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb_df = extract_tweets_into_df(\"data/tweets_#superbowl.txt\")\n",
    "#sb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb49_df = extract_tweets_into_df(\"data/tweets_#sb49.txt\")\n",
    "#sb49_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pat_df = extract_tweets_into_df(\"data/tweets_#patriots.txt\")\n",
    "#pat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hawks_df = extract_tweets_into_df(\"data/tweets_#gohawks.txt\")\n",
    "#hawks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "go_pat_df = extract_tweets_into_df(\"data/tweets_#gopatriots.txt\")\n",
    "#go_pat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # tweet for NFL = 396.971039\n",
      "Average # tweet for SB = 2067.824532\n",
      "Average # tweet for SB 49 = 1275.555746\n",
      "Average # tweet for Patriot = 750.632027\n",
      "Average # tweet for Go Hawks = 292.093264\n",
      "Average # tweet for Go Patriot = 40.888696\n"
     ]
    }
   ],
   "source": [
    "nfl_avg_tweet = get_average_tweet(nfl_df)\n",
    "sb_avg_tweet = get_average_tweet(sb_df)\n",
    "sb49_avg_tweet = get_average_tweet(sb49_df)\n",
    "pat_avg_tweet = get_average_tweet(pat_df)\n",
    "gohawks_avg_tweet = get_average_tweet(hawks_df)\n",
    "gopat_avg_tweet = get_average_tweet(go_pat_df)\n",
    "print(\"Average # tweet for NFL = %f\"%nfl_avg_tweet)\n",
    "print(\"Average # tweet for SB = %f\"%sb_avg_tweet)\n",
    "print(\"Average # tweet for SB 49 = %f\"%sb49_avg_tweet)\n",
    "print(\"Average # tweet for Patriot = %f\"%pat_avg_tweet)\n",
    "print(\"Average # tweet for Go Hawks = %f\"%gohawks_avg_tweet)\n",
    "print(\"Average # tweet for Go Patriot = %f\"%gopat_avg_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = [nfl_df,sb_df,sb49_df,pat_df,hawks_df,go_pat_df]\n",
    "#aggregated df\n",
    "df = pd.concat(frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-14 00:00:04-08:00\n",
      "2015-02-07 10:55:36-08:00\n",
      "587 hours\n"
     ]
    }
   ],
   "source": [
    "min_time = df.set_index('TimeStamp').index.min()\n",
    "max_time = df.set_index('TimeStamp').index.max()\n",
    "print (min_time)\n",
    "print (max_time)\n",
    "\n",
    "total_hours = (max_time - min_time)\n",
    "total_hours = total_hours.to_timedelta64().astype('timedelta64[h]') + 1\n",
    "print(total_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y = get_X_y(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "param_grid = {\"n_estimators\": [200, 400, 600, 800, 1000,1200, 1400, 1600, 1800, 2000],\n",
    "    \"max_depth\": [10, 20, 40, 60, 80, 100, 200, None],\n",
    "    \"max_features\": ['auto', 'sqrt'],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-294029187.03\n",
      "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(5, shuffle=True),scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=2, min_samples_split=5,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(random_state=0, n_estimators=1000, max_depth=20, max_features='sqrt', \n",
    "                                  min_samples_leaf=2, min_samples_split=5)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83614297785463843"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 98875098.0574\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.4f\" % mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=0,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_depth': [10, 20, 40, 60, 80, 100, 200, None], 'max_features': ['auto', 'sqrt'], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [2, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "GBmodel = GradientBoostingRegressor(random_state=0)\n",
    "GBgrid = GridSearchCV(estimator=GBmodel, param_grid=param_grid, cv=KFold(5, shuffle=True),scoring='neg_mean_squared_error')\n",
    "GBgrid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-405275402.696\n",
      "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(GBgrid.best_score_)\n",
    "print(GBgrid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67733631277709594"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBregressor = GradientBoostingRegressor(random_state=0, n_estimators=200, max_depth=20, max_features='sqrt', \n",
    "                                  min_samples_leaf=10, min_samples_split=2)\n",
    "GBregressor.fit(X_train, y_train)\n",
    "GBregressor.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = GBregressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 194702694.4346\n"
     ]
    }
   ],
   "source": [
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.4f\" % mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
